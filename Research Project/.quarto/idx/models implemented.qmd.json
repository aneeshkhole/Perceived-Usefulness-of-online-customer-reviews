{"title":"Models Implemented","markdown":{"headingText":"Models Implemented","headingAttr":{"id":"sec-models-implemented","classes":[],"keyvalue":[]},"containsRefs":false,"markdown":"\n```{python importsBlock}\nimport pandas as pd, numpy as np, matplotlib.pyplot as plt\nimport seaborn as sns\n# from sklearn import tree\nfrom sklearn.metrics import (\n    accuracy_score,f1_score,\n    precision_score,recall_score, \n    confusion_matrix, ConfusionMatrixDisplay,\n)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn import svm\nfrom imblearn.over_sampling import ADASYN, SMOTE\n\n\n\n```\n\n```{python DataImports}\nproduct_data = pd.read_csv('../data/master_product_list.csv')\nreview_orig = pd.read_csv('../data/reviews_with_stats.csv')\nreviews = pd.read_csv('../data/reviews_outlier_adjusted.csv')\nreviews['prodSiteID'] = reviews['prodSiteID'].str.upper()\nreview_orig['prodSiteID'] = reviews['prodSiteID'].str.upper()\nproduct_data['prodSiteID'] = product_data['prodSiteID'].str.upper()\n\nreviews = reviews.merge(\n    right=pd.DataFrame(\n      product_data[\n        [\n            'product_price','prodSiteID',\n            'prod_subjectivity','total_star_rating','site'\n        ]\n      ]\n    ),\n    on='prodSiteID',\n    how='left'\n)\n\nreview_orig = review_orig.merge(\n    right=pd.DataFrame(\n      product_data[\n        [\n            'product_price','prodSiteID',\n            'prod_subjectivity','total_star_rating','site'\n        ]\n      ]\n    ),\n    on='prodSiteID',\n    how='left'\n)\n\nreviews['is_helpful'] = np.select(\n    [\n        reviews['review_helpful_votes'] > 0,\n        (reviews['review_helpful_votes'] == 0) | (reviews['review_helpful_votes'].isna()),\n    ],\n    [\n        1,\n        0\n    ]\n)\n\nreview_orig['is_helpful'] = np.select(\n    [\n        review_orig['review_helpful_votes'] > 0,\n        (review_orig['review_helpful_votes'] == 0 )| (reviews['review_helpful_votes'].isna()),\n    ],\n    [\n        1,\n        0\n    ]\n)\n\ntest_metrics = pd.DataFrame(\n    {\n        'Model':[],\n        'Useful Level':[],\n        'Accuracy':[],\n        'F1':[],\n        'Precision':[],\n        'Recall':[]\n    }\n)\n\nreviews = reviews.dropna()\nreview_orig = review_orig.dropna()\n\ntmp = pd.DataFrame(\n    reviews[reviews['productID'].isin(list(range(1,16)))]\n)\n\ntrain_frame = pd.DataFrame(\n    tmp.sample(n=int(.8*len(tmp)))\n)\n\ntest_frame = pd.DataFrame(\n    review_orig.loc[~review_orig.index.isin(train_frame)]\n)\n```\n\n```{python DataTransforms}\nX_train,X_test,y_train,y_test= [\n    StandardScaler().fit_transform(np.array(train_frame[[\n        'review_star_rating_adjusted', 'review_helpful_votes_adjusted',\n        'review_subjectivity_adjusted', 'review_polarity_adjusted',\n        'review_length_adjusted','prod_subjectivity','total_star_rating'\n    ]])),\n    StandardScaler().fit_transform(np.array(test_frame[[\n        'review_star_rating', 'review_helpful_votes',\n        'review_subjectivity', 'review_polarity',\n        'review_length','prod_subjectivity','total_star_rating'\n    ]])),\n    np.array(train_frame['is_helpful']),\n    np.array(test_frame['is_helpful'])\n]\n```\n\n\n```{python PCATransforms}\npca = PCA()\npcs = pca.fit_transform(X_train)\npr_df = pd.DataFrame(data=pcs)\npr_df.columns = [\"PC{}\".format(i) for i in range(1,len(pca.components_)+1)]\nexp_var = pca.explained_variance_ratio_\ncum_var = np.cumsum(exp_var)\ncum_var_df = pd.DataFrame({\n    'Principal Component':[f'PC{i+1}' for i in range(len(cum_var))],\n    'Cumulative Variance':cum_var,\n    'Explained Variance':exp_var\n})\ncum_var_df\npca = PCA(n_components=6)\nw=pca.fit(X_train)\nX_train_pca=pca.transform(X_train)\nX_test_pca=pca.transform(X_test)\n```\n\nIn our modeling of the collected data, we seek to investigate several models for the generalization of the work performed by @percUse.\n\nWe will examine, compare, and contrast the use of the following models: \n\n* Multiple Linear Regression Prediction\n\n* Logistic Regression Classification\n\n* K-Nearest Neighbors Classification\n\n* Support Vector Machine Classification\n\n## Data Adjustments\n\nAs noted in our exploratory data analysis, each individual site has statistically significant differences in key variables we're considering in our modeling.  To mitigate the potential for under or overfitting, and misrepresentation due to variable scale we perform the following transformations to our data:\n\n<!--NOTE - need information here on specific variables under consideration for our modeling-->\n\n1. Variable outlier adjustment.  We noted in our EDA that each of the e-commerce platforms had high volumes of outliers with respect to the inter-quartile range.  We applied a transformation to our data to map any outlier variable value on a per-website basis from its value to $\\mu+3\\cdot sd(\\text{variable})$ for high-end outliers, and $\\mu-3\\cdot sd(\\text{variable})$ for low-end outliers.  In the event that either of these values exceeded the minimum or maximum value of the dataset, we mapped the value to the minimum or maximum accordingly.\n\n2. Standard scaling of variables.  After adjusting outliers, we re-mapped all of our feature variables to be on the scale from 0 to 1.\n\n3. Response variable transformation to binary value.  We denoted a single useful vote as meaning that the review was useful to customers, and mapped the value to True/1, and False/0 otherwise.\n\n4. Dimensionality Reduction via Principal Component Analysis.  To accelerate training and evaluation by our models, we...\n\nHere is a sample of our data prior to the transformation:\n\n```{python}\n\n```\n\nAnd here is a sample of our data after the applied transformations:\n\n```{python}\n\n```\n\n### Training Data\n\nTo train our dataset, we leveraged the data post-transformation to train each of our models, including the adjustments of outlier datapoints to being within 3 standard deviations of the mean of each variable.  We selected an 80% sample of this data and leveraged the same dataset to train each model.\n\n### Testing Data\n\nFor testing, we evaluated each model against transformed data, omitting the transformation of outliers to being within 3 standard deviations of the mean.  We performed this action to enable a fair comparison of each model against one another when working with real-world data.\n\n## Examination of the Original Multiple Linear Regression\n\n$\\hat{y} = \\beta_0 + \\beta_{polarity} + \\beta_{} +$\n\n### Violations of Linear Model Assumptions\n\n#### Lack of Linear Correlation\n\n#### Absence of Homoscedasticity on Normalized Data\n\n#### Absence of Normality in Residuals\n\n#### Lack of Confidence in t- and F-test results, $\\beta$ inference\n\n#### Conclusion on MLR model\n\nOn the above bases, the model fails to meet the required assumptions for a linear regression.  As such, our team rejects the multiple linear regression model as an effective means of predicting the perceived usefulness of review feedback on e-commerce websites for generalization.\n\n## Logistic Regression Classification\n\nWith the challenges of meeting and replicating the outcomes from @percUse for a MLR model, we proceeded onward to other options.  Our next choice for examination was logistic regression.  The MLR called for use of only numeric or continuous variables.  Logisitic regression enables us to examine the inclusion of additional categorical variables as part of the regression consideration.\n\n### Hyperparameter Tuning\n\nLogistic regression is one of the best performing models in the project after SVM. There are 3 logistic regression models - one was tuned using the class weight hyperparameter to address the class imbalance present in the dataset. By assigning a higher weight to the minority class (useful level 1) and a lower weight to the majority class (useful level 0), the model was able to better capture the patterns associated with the minority class, leading to improved performance metrics.\n\n### Oversampling techniques\n\nAdditionally, 2 more logistic regression models are trained using two oversampling techniques, namely ADASYN and SMOTE. ADASYN, which generates synthetic samples for the minority class based on their difficulty in learning regions, and SMOTE, which creates synthetic samples by interpolating between existing minority class samples, were used to address the class imbalance problem. These techniques help to provide the model with more balanced training data, allowing it to learn the characteristics of both classes more effectively.\n \nIt is a well know fact that oversampling techniques are employed if there a severe class imbalance if hyperparameter tuning does not improve the model performance. However, despite the heavy class imbalance, the tuned model and the SMOTE model achieve great result with 98% accuracy indicating that it is proficient at making correct predictions. 68% recall is decent but indicates that the model maybe classifying the positive instances from minority class incorrectly. \n\n\n<!--try to tweak and tune this model for better performance--> \n### Logistic Regression Test Results\n```{python LogRegBlock}\n\n#Logmod hyperparameter\n\nLogMod = LogisticRegression(class_weight={0:.3,1:.7})\nLogMod.fit(X_train_pca,y_train)\ny_pred = (LogMod.predict_proba(X_test_pca)[:,1]>0.25)\n\ntest_metrics.loc[len(test_metrics)] = {\n    'Model':'Logistic Regression (TUNED)',\n    'Useful Level': \"above 0\",\n    'Accuracy':accuracy_score(y_test,y_pred),\n    'F1':f1_score(y_test,y_pred),\n    'Precision':precision_score(y_test,y_pred),\n    'Recall':recall_score(y_test,y_pred)\n}\n# ConfusionMatrixDisplay(confusion_matrix(y_test,y_pred)).plot()\n# display(test_metrics)\n\n\n\n\n\n#### Logmod ADASYN\n\nadasyn = ADASYN()\nX_train_adasyn, y_train_adasyn = adasyn.fit_resample(X_train_pca, y_train)\nlogmod_adasyn = LogisticRegression()\nlogmod_adasyn.fit(X_train_adasyn, y_train_adasyn)\ny_pred_adasyn = logmod_adasyn.predict(X_test_pca)\n\n\ntest_metrics.loc[len(test_metrics)] = {\n    'Model': 'Logistic Regression (ADASYN)',\n    'Useful Level': \"above 0\",\n    'Accuracy': accuracy_score(y_test, y_pred_adasyn),\n    'F1': f1_score(y_test, y_pred_adasyn),\n    'Precision': precision_score(y_test, y_pred_adasyn),\n    'Recall': recall_score(y_test, y_pred_adasyn)\n}\n\n# ConfusionMatrixDisplay(confusion_matrix(y_test, y_pred_adasyn)).plot()\n# display(test_metrics)\n\nX_test_scaled = StandardScaler().fit_transform(X_test)\nX_test_pca = pca.transform(X_test_scaled)\n\n#### Logmod SMOTE\n\nsmote = SMOTE()\nX_train_smote, y_train_smote = smote.fit_resample(X_train_pca, y_train)\nlogmod_smote = LogisticRegression()\nlogmod_smote.fit(X_train_smote, y_train_smote)\n\ny_pred_smote = logmod_smote.predict(X_test_pca)\n\ntest_metrics.loc[len(test_metrics)] = {\n    'Model': 'Logistic Regression (SMOTE)',\n    'Useful Level': \"above 0\",\n    'Accuracy': accuracy_score(y_test, y_pred_smote),\n    'F1': f1_score(y_test, y_pred_smote),\n    'Precision': precision_score(y_test, y_pred_smote),\n    'Recall': recall_score(y_test, y_pred_smote)\n}\n\n\n# ConfusionMatrixDisplay(confusion_matrix(y_test, y_pred_smote)).plot()\n# display(test_metrics)\n\ntest_metrics_df = pd.DataFrame(test_metrics)\ndisplay(test_metrics_df)\n\n\nfig, axes = plt.subplots(1, 3, figsize=(18, 6))\n\nConfusionMatrixDisplay(confusion_matrix(y_test,y_pred)).plot(ax=axes[0])\naxes[0].set_title('Tuned Model')\n\nConfusionMatrixDisplay(confusion_matrix(y_test, y_pred_adasyn)).plot(ax=axes[1])\naxes[1].set_title('ADASYN')\n\nConfusionMatrixDisplay(confusion_matrix(y_test, y_pred_smote)).plot(ax=axes[2])\naxes[2].set_title('SMOTE')\n\nplt.tight_layout()\nplt.show()\n\n```\n\n\n\n## K-Nearest Neighbors Classification\n\n### Hyperparameter Tuning\n\n### KNN Test Results\n<!--try to tweak and tune this model for better performance--> \n```{python KnnBlock}\nknn = KNeighborsClassifier(n_neighbors=3)\nknn.fit(X_train_pca,y_train)\ny_pred = knn.predict(X_test_pca)\ntest_metrics.loc[len(test_metrics)] = {\n    'Model':'KNN',\n    'Useful Level':\"above 0\",\n    'Accuracy':accuracy_score(y_test,y_pred),\n    'F1':f1_score(y_test,y_pred),\n    'Precision':precision_score(y_test,y_pred),\n    'Recall':recall_score(y_test,y_pred)\n}\nConfusionMatrixDisplay(confusion_matrix(y_test,y_pred)).plot()\ndisplay(test_metrics)\n```\n\n## Support Vector Machine Classification\n\n### Hyperparameter Tuning\n\n### KNN Test Results\n\n```{python SVMBlock}\nspt_vector = svm.SVC(\n    kernel='poly',degree=1,probability=True,class_weight={0:0.1,1:0.9}\n).fit(X_train_pca,y_train)\n\ny_pred = spt_vector.predict(X_test_pca)\ntest_metrics.loc[len(test_metrics)] = {\n    'Model':'SVM-PCA',\n    'Useful Level':\"above 0\",\n    'Accuracy':accuracy_score(y_test,y_pred),\n    'F1':f1_score(y_test,y_pred),\n    'Precision':precision_score(y_test,y_pred),\n    'Recall':recall_score(y_test,y_pred)\n}\nConfusionMatrixDisplay(confusion_matrix(y_test,y_pred)).plot()\ndisplay(test_metrics)\n```\n\n## Model Comparison\n\nWe examine the following table to compare and contrast our implemented models on our collected data.\n\n```{python FinalResultsTable}\ntest_metrics\n```\n\nEach of these models had similar performance in terms of accuracy and precision. A key consideration for us is within the realm of recall in that false positives are potentially beneficial to the generalization of this model to identify reviews that are useful, but currently possess no helpful votes.  None of the models delivered any false positives, but having high recall may support identification of new, useful comments.\n\nThe top 2 performing models were our Support Vector Machine and Logistic Regression implementations.  Between the two, SVM had higher recall, which is preferable in our use case.  That being said, on every metric between the two models, there was near equivalent performance.\n\nSVM was a more challenging implementation, ...","srcMarkdownNoYaml":""},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":false,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","number-sections":true,"output-file":"models implemented.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.4.549","bibliography":["refs.bib"],"nocite":"@*\n","theme":["cosmo","custom.scss"],"page-layout":"full","smooth-scroll":true,"citations-hover":true,"link-citations":true,"grid":{"body-width":"1000px","sidebar-width":"150px"},"quarto-required":">= 1.4.0"},"extensions":{"book":{"multiFile":true}}},"pdf":{"identifier":{"display-name":"PDF","target-format":"pdf","base-format":"pdf"},"execute":{"fig-width":5.5,"fig-height":3.5,"fig-format":"pdf","fig-dpi":300,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":false,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"pdf","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":true,"merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":"../docs","link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"pdf-engine":"xelatex","standalone":true,"variables":{"graphics":true,"tables":true},"default-image-extension":"pdf","to":"pdf","toc":true,"output-file":"models implemented.pdf"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"block-headings":true,"bibliography":["refs.bib"],"nocite":"@*\n","quarto-required":">= 1.4.0","documentclass":"scrreprt","number-depth":4,"geometry":["margin=0.5in"],"link-citations":true,"header-includes":["\\usepackage{float}","\\usepackage{booktabs, caption, longtable, colortbl, array}","\\floatplacement{table}{H}","\\floatplacement{image}{H}"],"hyperrefoptions":["linktoc=all"]},"extensions":{"book":{"selfContainedOutput":true}}}},"projectFormats":["html","pdf"]}